{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzDAaroPm1kX",
        "outputId": "7b6f2aeb-20b4-48a3-c103-3f7664ba1101"
      },
      "outputs": [],
      "source": [
        "# !pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ1uxKlfnWmd",
        "outputId": "9db65e6e-17fe-493d-8fe4-8c0a9103fdb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Samples from tokenization: \n",
            "[b' her', b' mother', b' are', b' credited', b' with', b' having', b' researched', b',', b'\\n', b'authent', b'icated', b',', b' and', b' compiled', b' much', b' of', b' the', b' material', b' School', b'craft']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import tiktoken \n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "with open('poetry.txt', 'r', encoding='latin-1') as f:\n",
        "    _tokens = tokenizer.encode_ordinary(f.read())\n",
        "\n",
        "# sample tokens\n",
        "print(\"\\nSamples from tokenization: \")\n",
        "print([tokenizer.decode_single_token_bytes(token) for token in _tokens[150:170]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyKCz0sqnhO-",
        "outputId": "465a2fae-c204-4311-f2be-517077a669d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of tokens = 5475758\n"
          ]
        }
      ],
      "source": [
        "num_tokens = len(_tokens)\n",
        "vocab = list(set(_tokens))\n",
        "vocab_size = len(vocab)\n",
        "# ordinal_encodings\n",
        "\n",
        "otoe = {i : vocab[i] for i in range(vocab_size)}\n",
        "etoo = {vocab[i] : i for i in range(vocab_size)}\n",
        "# otoe = {i : _tokens[i] for i in range(num_tokens)}\n",
        "# etoo = {_tokens[i] : i for i in range(num_tokens)}\n",
        "ordinalize = lambda t : etoo[t]\n",
        "deordinalize = lambda t : otoe[t]\n",
        "\n",
        "tokens = [ordinalize(t) for t in _tokens]\n",
        "assert(_tokens == [deordinalize(t) for t in tokens])\n",
        "print(f'number of tokens = {len(tokens)}')\n",
        "assert(max(tokens) == vocab_size - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nbv2jUw8njWT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rohan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KZ8atLbnuxr",
        "outputId": "a902888e-c654-4070-fb09-6d1d218c0c81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device:cpu\n"
          ]
        }
      ],
      "source": [
        "batch_size = 16\n",
        "block_size = 32\n",
        "max_iters = 10000\n",
        "eval_iters = 500\n",
        "eval_interval = 500\n",
        "learning_rate = 1e-2\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_embd = 32\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "print(\"device:\" + device)\n",
        "dropout = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "34oJuhUAnynO"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        # if loss is not None:\n",
        "        #     if loss < 5.5:  \n",
        "        #         learning_rate = 1e-3\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5lY91UFn6qF",
        "outputId": "f59ff523-3635-470b-bccc-3605b7fb4073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5475758]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data = torch.tensor(tokens, dtype=torch.long, device=device)\n",
        "print(data.shape, data.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXKwROGyoEZw",
        "outputId": "4dfe74a4-97c3-4bb0-fa7c-c64be366cb97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "train_data = data[:int(num_tokens * 0.9)]\n",
        "val_data = data[int(num_tokens * 0.9): ]\n",
        "\n",
        "train_data.get_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "78FSwnj2oXh4"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == \"train\" else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i: i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "\n",
        "xb, yb = get_batch(\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcje85ytomvN",
        "outputId": "ad78d3bb-fd73-4432-cf1e-439d2dff3276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 32])\n",
            "torch.Size([16, 32])\n"
          ]
        }
      ],
      "source": [
        "print(xb.shape)\n",
        "print(yb.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uNBrTPhuorRw"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = BigramLanguageModel(vocab_size)\n",
        "m = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "a8KOcjmUoumc"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCAOW5XBoxMr",
        "outputId": "f11882a3-ddff-4707-e884-501b357083d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.146535 M parameters\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfjrOAuHozAY",
        "outputId": "c10f02da-3c69-43e6-91ac-3a085149b7bf"
      },
      "outputs": [],
      "source": [
        "# for x in range(5):\n",
        "  \n",
        "#   for iter in range(max_iters):\n",
        "\n",
        "#       # every once in a while evaluate the loss on train and val sets\n",
        "#       if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "#           losses = estimate_loss()\n",
        "#           print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "#       # sample a batch of dat\n",
        "#       xb, yb = get_batch('train')\n",
        "\n",
        "#       # evaluate the loss\n",
        "#       logits, loss = model(xb, yb)\n",
        "#       optimizer.zero_grad(set_to_none=True)\n",
        "#       loss.backward()\n",
        "#       optimizer.step()\n",
        "\n",
        "#   model_name = \"Model_iter_\" + str(50000 + (x+1)*max_iters)\n",
        "#   torch.save(model.state_dict(), model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rSNZ3SZjslZ",
        "outputId": "65ab5492-3752-4810-e8e9-1da367dcc511"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32231"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-7PFCY596jae"
      },
      "outputs": [],
      "source": [
        "model2 = BigramLanguageModel(vocab_size)\n",
        "m2 = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pO7xP7cP9Wp",
        "outputId": "c8562bab-17ce-49c5-9d6c-dd0c8820c7c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "m2.load_state_dict(torch.load(\"Model_iter_50000 (1)\", map_location=torch.device(device)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "eEqKzsenpksd"
      },
      "outputs": [],
      "source": [
        "# torch.save(model.state_dict(), \"Model_iter_80000\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTlRcaxnpDRr",
        "outputId": "0b6edd73-14e0-45a6-960b-3619fa724ad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 132])\n"
          ]
        }
      ],
      "source": [
        "xb, yb = get_batch('val')\n",
        "_idx = model.generate(xb, 100)\n",
        "\n",
        "print(_idx.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObbKKATRpHOU",
        "outputId": "bd28e875-1614-4bad-d826-dbe6c9064692"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "As Rome ne'er saw;\n",
            "They a' maun meet some ither place,\n",
            "Willie's awa!\n",
            "Poor Burns ev'n Scotch hue andof by us!\n",
            "Re call on the world a wars mention of tone\n",
            "Sobd over.  TheATSure and Private McPivening forever again alone an English poets of Troy?\"\n",
            "His sacrifice, and wept not feignage,\n",
            "Was we are ta''s swept brighter eyes, and now your marvel so of the grave\n",
            "Oppants well as I shall their life in me,\n",
            "Well done sentient things;\n",
            "The as I'd here if made to\n",
            ",\n",
            "The jealous City, whispering always -- \"Home!\"\n",
            "Space, and the twelve clean winds of heaven,\n",
            "This is Tai Shan, the beautiful, calling him.]  Bell Engels spot: \"Foss\", \"OCH Son of she fears\n",
            "\"'The checarden with the birds of slender heart, straight.\n",
            "as built their life, or passed when Ast Maria, turningigh:  It are foulness;\n",
            "That fled the shore, who saw the little child!\n",
            "Were, whose secret tide! what is at the front of good glorious is;\n",
            "He fled with what it will fail!  \"Take the earth? \n",
            ", silly body, see him;\n",
            "Nae wonder he's as black's the grun,\n",
            "Observe wha's standing wi' him.\n",
            "Your speech to keep him he when he sat and a wont greatly promise is before;\n",
            "The City32) by Marphisa's mourning maid ambuscans, the river:\n",
            "And are sorcery,\n",
            "Passes to take in light Eaint Cl morals,\n",
            "Chilled as though quiet rain about the vast and yet\n",
            "Of leaves their loth claimed\n",
            "A storm is consuming absence out to the shade,\n",
            "Stopped still wild wind seemed becomingiseO, might may witness would hear for overwhelm\n",
            " palace and yon gardens fine!\n",
            "The world then the love should know\n",
            "I bear my Highland Lassie, O.\n",
            "But fickle fortune frown, \"As though I say sore gold is laid itiddide you said:\n",
            "\"If it as the iron to fold thee blindly bless distinguishMore speaking even lately the Pror wolf, pay on it come\n",
            "God's fury, single drop beneath this way.\"\n",
            "No precious miles of the false cranks among the valley.\n",
            "She's place the gay moonsh\n",
            "In furious troops; and sparks. 34-bolts attentive view and tov.\n",
            "Though hast, thou face was\n",
            " when the Spring\n",
            "Begins its first wild dance,\n",
            "Love redder than the rose,\n",
            "Love paler than the snows,\n",
            "Love frail as the soul and consuming veil,\n",
            "And lies but proven before a Slia.   The Greeks\n",
            "In hearts that nonekes and theWitness hire Abime\n",
            "The tongue foretold him wel: the so large thing the nathe too;\n",
            "And from his bagBarst to dewatha\n",
            "And Gareth cried aloud the fer a word,\n",
            "almost,yles,\n",
            "Durous King and the powerful vengeance the king,\n",
            "And then? Sanctus'd from that fabulous from behind on\n",
            "\n",
            "Song--Montgomerie's Peggy\n",
            "The Ploughman's Life\n",
            "Song--Here's To Thy Health\n",
            "I'll Go And Be A Sodger and triumph from the good manage.\n",
            "Thus his father's Bonuxino reverent\":\n",
            "Recound: unbion's edISH and plit of spreading high larboard.\n",
            "Of shadows on his heaven her assault your camp-smoke and milk.\n",
            "Achaking upon my living quiverre stands on each bar.\n",
            "Mr.  foreknowledge bold on all attempts'd\n",
            "(Untogetherision from infinite sword.]xt game asked the flaming load Rollanz,\n",
            "That obsc\n",
            " by dint of merit,\n",
            "In his sly, dry, sententious, proverb way!\n",
            "He bids you mind, amid your thoughtless rattle,\n",
            "With the finger, ceases to the coming dear and she;\n",
            "Then in fashion wrought in my wings, nor voice he stayed.\"\n",
            "\"Ewellest light ago of mine confess to reply a golden bloom.\n",
            "Rogero: venturesome through\n",
            "As waits that the triumph saints, when he rushed grapes, and when Friend\n",
            "A statue but all Flamthe men I did let the loving\n",
            "As to his virgin lady, and only maid74!--\n",
            "The offence, which magic made Beatrice\n",
            ", when she came this way,\n",
            "Sweet bents would bow, to give my Love the day;\n",
            "And when at night she folded had her sheep, who rest,\n",
            "E put would I artnings stillget thee, by thee--ar'ns\n",
            "'Dilled, and nothing noblances.  How cease from hand\n",
            "Draws a will I have ceased.\n",
            "Hangs of the stars, while the storied root.\n",
            "Thued ( fifth knew, the lock'd eye of elements with his fury holly crown\n",
            "But impious with the air.\n",
            "The oil'mpit sank, who came to the prey,\n",
            "\n",
            " September?\n",
            "Or gather hazel nuts among the thickets\n",
            "On Aaron Hatfield's farm when the frosts begin?\n",
            "For many times with the laughing!\n",
            "Perhaps beneath them his three as that nuptuous deeds.\n",
            "A chewing forthwith they fill, e'n love or read Love,\n",
            "The cause part of November free for will have I feel\n",
            "\"Yes, for pass and corn, the comet's sonatails.\n",
            "Your mission, with the\n",
            "About what parting wish what to pray and Peter will be our view the Father, and evermore\n",
            "This, her early be strange familiarness famous homely, and 'tis\n",
            "!\n",
            "The ragged followers o' the Nine,\n",
            "Poor, thoughtless devils! yet may shine\n",
            "In glorious light,\n",
            "While sordid sons of future, thou arise,\n",
            "Had, who may more to nor seek it in the Lizard turn to Ryan\n",
            "In love is thinner ready to spied\n",
            "Than eclipseath a tranquil songs may better far hole by the tone.\n",
            "Or soon as he cried to you\n",
            "Den as I have\n",
            "As to thy aid me her heaven, however somewhat wont to dance,\n",
            "In spread feet the tents the mighty brave, murder reignment.\n",
            "andorum.\n",
            "Of many his great senses\n",
            "\n",
            " Echo is no more.\n",
            "Ye jarring, screeching things around,\n",
            "Scream your discordant joys;\n",
            "Now, half your din of tuneless fence!\n",
            "Witholy tendericious by truth and heat, and with it,\n",
            "Above; since not still the kingdom come'd root.\n",
            "Of pictures of heroes alludes say--\n",
            "The rival saw that in by blackness of dexterity\n",
            "Well.\n",
            "Mrs.There, \"This that tranquil triumph throughflaugoday,\n",
            "Shall make the days, as at glittering forth before\n",
            "Dork wrins.  The simplicity.]  Purg3)\n",
            "Siter, and suggested food\n",
            ",\n",
            "As on the banks of Ayr I stray'd,\n",
            "And singing, lone, the ling'ring hours,\n",
            "I shelter in thy honour'd Clerbino dear age, brown dismaye nor mine eyes\n",
            "In name had the doom.\n",
            "And heard it descended in a place perhaps means more.\n",
            " reflected burns with heat and hidden than dreams revolution out, whirled\n",
            "Hold the dragon's beam was long load,\n",
            " is holy wings, when, as that himself of far pyreate\n",
            "Had said in her Cardinals he raised her chair forward little things,\n",
            "Dead of evil father shall I blend,\n",
            "In hard battle and twenty years\n",
            " on his back!\n",
            "For us and for our Stage, should ony spier,\n",
            "\"Whase aught thae chiels maks a'er-stick\n",
            "Amon continued his lissnor than through the other divided!\n",
            "Whose wont to the glory and I leave\n",
            "Still your conduct of the Gods together and\n",
            "The force or barbaric every heart resolve with fluttering winding gate nor ends.\n",
            "The father lost,\n",
            "Thither mature at passion's--\n",
            "(18) Nor was at ending that himself that voice, or twice to\n",
            "Hero here was lured front cheers to hence Achilles, wondering\n",
            "Hath have granted them.\n",
            "ed with the dashing roar;\n",
            "Or when the North his fleecy store\n",
            "Drove thro' the sky,\n",
            "I saw grim Nature's visage of vitors there was wors with a funny Highness;\n",
            "Where brink though a bud and the fine:\n",
            "Encicit of this faith had, which Claus was nurs loud \"Al his say;\n",
            "Why mines the hallow'd scars is darkened\n",
            "From fittest fors' a track.\"  Not beast I may in the sea--;\n",
            "You take my great\n",
            "Do grownlessly indeed in mouth rebellious bent; for stone is ours beneath I thrant or\n",
            "As\n",
            " war,\n",
            "And oft repell'd th' invader's shock.\n",
            "With awe-struck thought, and pitying tears,\n",
            "I view that should so the wit undue brother, rushed a glorious part\n",
            "\n",
            "Where da', too the black glass\n",
            "And often cried in sight are backward he,\n",
            "These!   Send bonlooking miles, putting away.\n",
            "Calanius;\n",
            "At lasteth in the work of Thirdasing buried,\n",
            "They sweeter stems of Achilles, in this blue\n",
            "Conmind lepared, as fast his bands and of gold\n",
            "or to make thedeath, a redundant,\n",
            "Ef diminceedd\n",
            " that longeth forgetteth\n",
            "The warmth and the moisture too.\n",
            "In the hot sun rising and setting\n",
            "There is naught save feverish pain;\n",
            "And Turnus bore the qu fledgling lord with scorn.\n",
            " sought as I call the stainless feet.\n",
            "\"Now that vanquished wing; his bosomco and to strength\n",
            "The knight to vacOUGH cruel reply,\n",
            "Who bright, who go down the point it care in Ba,\n",
            "Sprched bar, grow through studs, from his shoulders fields as air\n",
            "With North ark you would-brain ta'n\n",
            "The de King in the easy daughter: Archbishop veine followers.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for batch in _idx:\n",
        "    res = []\n",
        "    for num in batch:\n",
        "        num2 = deordinalize(int(num))\n",
        "        res.append(num2)\n",
        "    resstr = tokenizer.decode(res)\n",
        "    print(resstr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5xtZudtCpTI9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# xb, yb = get_batch('train')\n",
        "# _idx = model.generate(xb, 100)\n",
        "\n",
        "# print(_idx.shape)\n",
        "\n",
        "# for batch in _idx:\n",
        "#     res = []\n",
        "#     for num in batch:\n",
        "#         num2 = deordinalize(int(num))\n",
        "#         res.append(num2)\n",
        "#     resstr = tokenizer.decode(res)\n",
        "#     print(resstr)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzDAaroPm1kX",
        "outputId": "7b6f2aeb-20b4-48a3-c103-3f7664ba1101"
      },
      "outputs": [],
      "source": [
        "# !pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ1uxKlfnWmd",
        "outputId": "9db65e6e-17fe-493d-8fe4-8c0a9103fdb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Samples from tokenization: \n",
            "[b' her', b' mother', b' are', b' credited', b' with', b' having', b' researched', b',', b'\\n', b'authent', b'icated', b',', b' and', b' compiled', b' much', b' of', b' the', b' material', b' School', b'craft']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import tiktoken \n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "with open('poetry.txt', 'r', encoding='latin-1') as f:\n",
        "    _tokens = tokenizer.encode_ordinary(f.read())\n",
        "\n",
        "# sample tokens\n",
        "print(\"\\nSamples from tokenization: \")\n",
        "print([tokenizer.decode_single_token_bytes(token) for token in _tokens[150:170]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyKCz0sqnhO-",
        "outputId": "465a2fae-c204-4311-f2be-517077a669d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of tokens = 5475758\n"
          ]
        }
      ],
      "source": [
        "num_tokens = len(_tokens)\n",
        "vocab = list(set(_tokens))\n",
        "vocab_size = len(vocab)\n",
        "# ordinal_encodings\n",
        "\n",
        "otoe = {i : vocab[i] for i in range(vocab_size)}\n",
        "etoo = {vocab[i] : i for i in range(vocab_size)}\n",
        "# otoe = {i : _tokens[i] for i in range(num_tokens)}\n",
        "# etoo = {_tokens[i] : i for i in range(num_tokens)}\n",
        "ordinalize = lambda t : etoo[t]\n",
        "deordinalize = lambda t : otoe[t]\n",
        "\n",
        "tokens = [ordinalize(t) for t in _tokens]\n",
        "assert(_tokens == [deordinalize(t) for t in tokens])\n",
        "print(f'number of tokens = {len(tokens)}')\n",
        "assert(max(tokens) == vocab_size - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nbv2jUw8njWT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rohan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KZ8atLbnuxr",
        "outputId": "a902888e-c654-4070-fb09-6d1d218c0c81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device:cpu\n"
          ]
        }
      ],
      "source": [
        "batch_size = 16\n",
        "block_size = 32\n",
        "max_iters = 10000\n",
        "eval_iters = 500\n",
        "eval_interval = 500\n",
        "learning_rate = 1e-2\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_embd = 32\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "print(\"device:\" + device)\n",
        "dropout = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "34oJuhUAnynO"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        # if loss is not None:\n",
        "        #     if loss < 5.5:  \n",
        "        #         learning_rate = 1e-3\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5lY91UFn6qF",
        "outputId": "f59ff523-3635-470b-bccc-3605b7fb4073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5475758]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data = torch.tensor(tokens, dtype=torch.long, device=device)\n",
        "print(data.shape, data.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXKwROGyoEZw",
        "outputId": "4dfe74a4-97c3-4bb0-fa7c-c64be366cb97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "train_data = data[:int(num_tokens * 0.9)]\n",
        "val_data = data[int(num_tokens * 0.9): ]\n",
        "\n",
        "train_data.get_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "78FSwnj2oXh4"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == \"train\" else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i: i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "\n",
        "xb, yb = get_batch(\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcje85ytomvN",
        "outputId": "ad78d3bb-fd73-4432-cf1e-439d2dff3276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 32])\n",
            "torch.Size([16, 32])\n"
          ]
        }
      ],
      "source": [
        "print(xb.shape)\n",
        "print(yb.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uNBrTPhuorRw"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = BigramLanguageModel(vocab_size)\n",
        "m = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "a8KOcjmUoumc"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCAOW5XBoxMr",
        "outputId": "f11882a3-ddff-4707-e884-501b357083d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.146535 M parameters\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfjrOAuHozAY",
        "outputId": "c10f02da-3c69-43e6-91ac-3a085149b7bf"
      },
      "outputs": [],
      "source": [
        "# for x in range(5):\n",
        "  \n",
        "#   for iter in range(max_iters):\n",
        "\n",
        "#       # every once in a while evaluate the loss on train and val sets\n",
        "#       if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "#           losses = estimate_loss()\n",
        "#           print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "#       # sample a batch of dat\n",
        "#       xb, yb = get_batch('train')\n",
        "\n",
        "#       # evaluate the loss\n",
        "#       logits, loss = model(xb, yb)\n",
        "#       optimizer.zero_grad(set_to_none=True)\n",
        "#       loss.backward()\n",
        "#       optimizer.step()\n",
        "\n",
        "#   model_name = \"Model_iter_\" + str(50000 + (x+1)*max_iters)\n",
        "#   torch.save(model.state_dict(), model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rSNZ3SZjslZ",
        "outputId": "65ab5492-3752-4810-e8e9-1da367dcc511"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32231"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-7PFCY596jae"
      },
      "outputs": [],
      "source": [
        "model2 = BigramLanguageModel(vocab_size)\n",
        "m2 = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pO7xP7cP9Wp",
        "outputId": "c8562bab-17ce-49c5-9d6c-dd0c8820c7c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "m2.load_state_dict(torch.load(\"Model_iter_50000 (1)\", map_location=torch.device(device)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eEqKzsenpksd"
      },
      "outputs": [],
      "source": [
        "# torch.save(model.state_dict(), \"Model_iter_80000\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTlRcaxnpDRr",
        "outputId": "0b6edd73-14e0-45a6-960b-3619fa724ad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 132])\n"
          ]
        }
      ],
      "source": [
        "xb, yb = get_batch('val')\n",
        "_idx = model.generate(xb, 100)\n",
        "\n",
        "print(_idx.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObbKKATRpHOU",
        "outputId": "bd28e875-1614-4bad-d826-dbe6c9064692"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ", frightened light,\n",
            "And stoop His cheek\n",
            "And say\n",
            "\"`My angels must not send so frail a thing\n",
            "To light the West.\n",
            "Promaces mournful, suddenly on the heroic stars\n",
            "Take my sleepingworm white glee, and marble English prince;\n",
            "Thence to combat murmuring German and Book spoke -- -\n",
            "His own passage in Norse aspirations of eyebrow and cast\n",
            "He drew willing out nothing streams espied. Or deity\n",
            "Or he possessed the sweaty cloister himself who with his fearsgate.  When storms\n",
            "Unrieved rightly should seem to seize his foes and Celtagon,\n",
            "Our sins, meteor at dum\n",
            ".\n",
            "Mine ear, awake to silence, can foretell\n",
            "The cuckoo's fitful bell.\n",
            "I wander in a grey time that encloses, in the queen;\n",
            "And leaning on the animals.\n",
            "More spacious flock, however beneath his chaste the convent flower of adore,\n",
            "Of Arcadian \"The heat since that, and I can say, and these offence\n",
            "And send comes and hateful be ye harm game up into life,\n",
            "Their help on he with,\n",
            "quied, bad attribute falling discreet,\" spinged low, bothe and one,\n",
            "Were all night was constraining she feasting not to see to\n",
            " the glinting acres,\n",
            "\"In his soul, mayhap,\n",
            "Something like a wheat-dream\n",
            "Quickens into shape!\"\n",
            "Sang the ocean image and pleasant its youthful friends;\n",
            "Till he bent before that fancy overthrown higher day,\n",
            "It was not speak and rushed, I know\n",
            "Andacus' feats to soar in hear despair carved deserts\n",
            "Without base rivals with her stand intercepted:\n",
            "I lived, every wind.   Trinacus, and power like a reverence\n",
            "And speak to him with burning all say:\n",
            "and it led in forevermore with my tongue fought as old--\n",
            "The interposed, at\n",
            " the hills of Habersham,\n",
            "Far from the valleys of Hall.\n",
            "All down the hills of Habersham,        Onhips on JOSIT cried.  Vaf and most rage, while gifes:\n",
            "Balk or clown, resign the-haired to life\n",
            "--\n",
            "Sila were Pap situated re'rds the deed stretched,\n",
            "under\n",
            "But Joachethe's Venus of ancient queen,\n",
            "EToofounded Ausps drew blind,\n",
            "And the splinters of His eager as he came the Britain, an' sonthe greatboth himself.\n",
            "Pra which who whisper, sweet\n",
            " hurdies like a distant hill,\n",
            "Your pin was help to mend a mill\n",
            "In time o'need,\n",
            "While thro' your pores the dews,\n",
            "Their roses thrills and ere the mere\n",
            "Khee, and they through velecting foam,\n",
            "When that friends the bell'\n",
            "Made us trim green world they soar o'ry\n",
            "AND Medea, than a blue, &;\n",
            "I from the holyly, Capur'd his ways,\n",
            "In sevens in furlish tempt the blessed monarch's country of three Troysettin' prfalle, to sides\n",
            "Bene\n",
            "\"Each Euryp of\n",
            " more than an hour at a time,\n",
            "Because Thomas Rhodes ran the church\n",
            "As well as the store and the bank.\n",
            "So while I was tying my soul swelled endure\n",
            "By the propre that none exceed those are paths\n",
            "And then by firemon earthly sacrifice to dig delicate pathway to sniff.\n",
            "Straight to bra cloak; and I have her did know,\n",
            "The eyes have dared in battle bes remnant for\n",
            "Obing of another forsook my silence and in fine.'\n",
            " sad .  But now!\"  \"and swung dead, in arms the sight,\n",
            "And faces were slowly stubborn thee knowledgeme\n",
            "And by all the monstrous\n",
            "ickett's cow\n",
            "Roped out to grass, and free you know as far\n",
            "As the length of the rope.\n",
            "One day while arguing so,blown; each other way to some name advancing\n",
            "Your spirits greatly they are velutch,\n",
            "I am to smile.\n",
            "Yea, and them strangely vanishiffs. lated by the goddess's soul, like Raymond\n",
            "Belling the horse, in their hand.\n",
            "Their volatile Swede died; fallen I only now have lost Lord\n",
            "\"Romicon protectede lay and thou raised about by him is;\n",
            "I flednimper'd like his hand an surely 'gainst not\n",
            "*\n",
            "to him\n",
            "\"Who never turned his back, but marched breast forward,\n",
            "Never doubted clouds would break,\n",
            "Never dreamed, though right were worst of the Nis the eyes\n",
            "And down against that side his game,\n",
            "Think like design did to the while Ossa!   And from him him thus parting cold\n",
            "eline'd to that being, and fastens lines.\n",
            "Such pause in the roof mount.ORD - indifference\n",
            "Of subject sign of Italy not endure and I fell,\n",
            "The three, when the cliff Gigregnannaute motion thought, \"Look--belable, is over and lay,\n",
            "The defined\n",
            " to return!\n",
            "Scenes, if in stupor I forget,\n",
            "Again I feel, again I burn!\n",
            "From ev'ry joy and pleasure or to sit!\",\n",
            "That stayed the trust thee and thus I take a throne and fair conception ash.\n",
            "The singer, loyal youngly shine and he (Enough was sober wormque right unto me,\n",
            "It is some roindle and well a kindled bent\n",
            "My April on the fuf chasms of feminine, the French charge,\n",
            "Made looking on ro lord and the river Argans.\n",
            "Turn'd to sails upon his horse arm and Acest level'd:\n",
            "'er\n",
            " beech,\n",
            "And whisperings clear as Pan's.\n",
            "It led me with its childlike charm,\n",
            "As candor leads desire,\n",
            "Now with arms unjust, as limor trade of God would have Egang waked cage.\n",
            "v. tho'n who mintage Charles and in\n",
            "In-Around them a middle, a fourth yearicip I drew,\n",
            "The lofty throne thou shalt slaughtered in that have best poundsring graves\n",
            "Had found. ull love was Angelica,\n",
            "I saw, some bathing, and her point oracles still between,\n",
            "At 132, blessedness, Father's a purse from he said,\n",
            "\n",
            " to destroy the last vestige\n",
            "Of my memory and influence.\n",
            "For those of you who could not see the virtue\n",
            "Of knowing Volney's \"Ruin\n",
            "A purest zaunageian Troyened,\n",
            "A blend of vast of gift for dread ritese\n",
            "SINNA\n",
            "Not the look to seide with this impert to get over-past;\n",
            "B rogue within a second caw espied,\n",
            "Was Caesar thrive and 'ath theicken fader image, and Sighs of thetelf,\n",
            "The slumbling a man, \"Brep thou\n",
            "For and I eyes of appearance's mai sank.\n",
            " I answer yes --\n",
            "Word beautiful and true.\n",
            "By this I'll sew the bridal dress\n",
            "I shall put on for you.\n",
            "Before I die were white\n",
            "If they saweth and parted, and I found himself appears,\n",
            "Remember that held me babble and cry to security.\n",
            "\"Armed and the hurt he threats justly abbids\n",
            "But in some body with promise vain, then, Villani round an( ready arts and urge thee an eye slew-ords.\n",
            "This craft of suppt up to the load and of gifts\n",
            "Leiron cried.\"  On he cried,\n",
            "While as a utt with pledge\n",
            "Ye haz'ly shaws and briery dens!\n",
            "Ye burnies, wimplin' down your glens,\n",
            "Wi' toddlin din,\n",
            "At circles, but sail the mountain's warranted the field in\n",
            "Man's lagg, etc.  Peram to joy and for peace shalt guess here,\n",
            "\"Only a sharp as upon the gift undistred,\n",
            "To spread that his Lord's the forest below.\n",
            "That ocean ere' platforms encounter were tramp\n",
            "minute-sent with their standard and shorten.\n",
            "What, more to expir mind,\n",
            "For Rogero said it believe leaps by mine kin.\n",
            "\n",
            "'s;\n",
            "He saw her days were near-hand ended,\n",
            "But, wae's my heart! he could na mend it!\n",
            "He gaped this he went to the mantle inst fixpthe made,\n",
            "Of this voice of likly gret terrible,\n",
            "Had kept the I hadde a thin yon hy blood,\n",
            "Put out his o'er winner that blow.\n",
            "Himn Bard contingcheet by this world is.\n",
            "For she serveth into the kinde avis'd me,\n",
            "May the kings they turn up on, pale silence were enough to splendour sore\n",
            "Ere gray a couple\n",
            "We can't think quite that the katydids and frogs\n",
            "And the little crying chickens and the little grunting hogs,\n",
            "And the other living, implored them them jasper> vantage drew,\n",
            "The cunning beastsest when we cries reviv',\n",
            "Of standing by the little ones!)\n",
            "me were now, the hill from the rewardedposed from the stars:\n",
            "In is ancitrant his years-waraline and run\n",
            "Where it capides.  sometimes dandy rocks!\n",
            "He ponder and with whose craving aid above,\n",
            "Over the school still. ored his name bright or free\n",
            "These radiant, and this peaceful\n",
            " break and flower in beauty,\n",
            "Along her veins they glisten and ring and burn. . . .\n",
            "He hears his own slow steps tread down to distild appears.\n",
            "(ll.\n",
            "Oh!  In thine had buried think now Divine,\n",
            "With Reveser tamander rested may awake\n",
            "Clanking to kill will cease from this lonely dawn --\n",
            "What were four things now hard,\n",
            "Of bitter prince Charles and slow-like force toiltering flights.  By the Origial band,\n",
            " variousitable Sabing brand:\n",
            "The first voice uplifted where he had ease his polish'd to that be\n",
            "Screams a\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for batch in _idx:\n",
        "    res = []\n",
        "    for num in batch:\n",
        "        num2 = deordinalize(int(num))\n",
        "        res.append(num2)\n",
        "    resstr = tokenizer.decode(res)\n",
        "    print(resstr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5xtZudtCpTI9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# xb, yb = get_batch('train')\n",
        "# _idx = model.generate(xb, 100)\n",
        "\n",
        "# print(_idx.shape)\n",
        "\n",
        "# for batch in _idx:\n",
        "#     res = []\n",
        "#     for num in batch:\n",
        "#         num2 = deordinalize(int(num))\n",
        "#         res.append(num2)\n",
        "#     resstr = tokenizer.decode(res)\n",
        "#     print(resstr)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
